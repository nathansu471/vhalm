#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸‹è½½ COCO 2017 å­é›†ï¼ˆå›¾ç‰‡ + Captionsï¼‰
ä¿®æ­£ç‰ˆï¼šä¿è¯ captions_subset.json ä¸ images å®Œå…¨å¯¹åº”
ä½œè€…: å¶åœ£å°§
"""

import os
import json
import random
import requests
from tqdm import tqdm

# ======================
# âš™ï¸ å‚æ•°è®¾ç½®
# ======================
NUM_IMAGES = 3000
OUT_DIR = "./coco_subset"
ANNOTATION_FILE = "captions_train2017.json"
ANNOTATION_URL = "http://images.cocodataset.org/annotations/annotations_trainval2017.zip"
BASE_URL = "http://images.cocodataset.org/train2017/"

os.makedirs(f"{OUT_DIR}/images", exist_ok=True)

# ======================
# ğŸ“¦ Step 1. ä¸‹è½½ caption æ–‡ä»¶
# ======================
if not os.path.exists(ANNOTATION_FILE):
    print("â¬‡ï¸ æ­£åœ¨ä¸‹è½½ captions_train2017.json ...")
    os.system("wget -q http://images.cocodataset.org/annotations/annotations_trainval2017.zip")
    os.system("unzip -q annotations_trainval2017.zip 'annotations/captions_train2017.json'")
    os.system("mv annotations/captions_train2017.json .")
    os.system("rm -r annotations annotations_trainval2017.zip")

# ======================
# ğŸ“– Step 2. åŠ è½½æ•°æ®
# ======================
with open(ANNOTATION_FILE, "r", encoding="utf-8") as f:
    data = json.load(f)

images = data["images"]
annotations = data["annotations"]

print(f"ğŸ“¸ æ€»å›¾ç‰‡æ•°: {len(images)}, æ€»captionæ•°: {len(annotations)}")

# å»ºç«‹æ˜ å°„ï¼šimage_id -> file_name
id_to_name = {img["id"]: img["file_name"] for img in images}

# ======================
# ğŸ¯ Step 3. éšæœºæŠ½å–3000å¼ å›¾ç‰‡
# ======================
subset_images = random.sample(images, NUM_IMAGES)
subset_ids = {img["id"] for img in subset_images}
subset_fnames = {img["file_name"] for img in subset_images}

# ======================
# ğŸ’¬ Step 4. æ”¶é›†captionï¼ˆå®‰å…¨æ˜ å°„ï¼‰
# ======================
captions_dict = {name: [] for name in subset_fnames}
for ann in annotations:
    img_id = ann["image_id"]
    if img_id in subset_ids:
        fname = id_to_name[img_id]
        captions_dict[fname].append(ann["caption"])

# ======================
# ğŸ–¼ Step 5. ä¸‹è½½å›¾ç‰‡
# ======================
for fname in tqdm(subset_fnames, desc="Downloading images"):
    url = BASE_URL + fname
    save_path = os.path.join(OUT_DIR, "images", fname)
    if not os.path.exists(save_path):
        try:
            r = requests.get(url, timeout=10)
            if r.status_code == 200:
                with open(save_path, "wb") as f:
                    f.write(r.content)
            else:
                print(f"âŒ ä¸‹è½½å¤±è´¥: {fname} (status {r.status_code})")
        except Exception as e:
            print(f"âš ï¸ ç½‘ç»œé”™è¯¯: {fname} ({e})")

# ======================
# ğŸ’¾ Step 6. ä¿å­˜ captions_subset.json
# ======================
subset_data = []
for fname in sorted(subset_fnames):
    subset_data.append({
        "img_id": fname,
        "captions": captions_dict[fname]
    })

out_json = os.path.join(OUT_DIR, "captions_subset.json")
with open(out_json, "w", encoding="utf-8") as f:
    json.dump(subset_data, f, indent=2, ensure_ascii=False)

print(f"\nâœ… å…±ä¿å­˜ {len(subset_data)} å¼ å›¾ç‰‡")
print(f"âœ… captions_subset.json ä½äº: {out_json}")
print(f"âœ… å›¾ç‰‡ä¿å­˜è·¯å¾„: {OUT_DIR}/images/")
