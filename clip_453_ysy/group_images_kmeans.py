import numpy as np
import json
from sklearn.cluster import KMeans
from tqdm import tqdm
import random

# === è·¯å¾„è®¾ç½® ===
features_path = "image_features.npy"
ids_path = "image_ids.json"
captions_path = "coco_subset/captions_subset.json"
output_path = "image_groups_with_captions.json"

# === Step 1. åŠ è½½æ•°æ® ===
print("ğŸ”¹ åŠ è½½è§†è§‰ç‰¹å¾ã€å›¾ç‰‡IDä¸captionä¸­...")
features = np.load(features_path)

with open(ids_path, "r") as f:
    img_ids = json.load(f)

with open(captions_path, "r") as f:
    captions_data = json.load(f)

# captions_subset.json æ ¼å¼å‡è®¾ä¸ºï¼š
# [
#   {"img_id": "000000123456.jpg", "captions": ["a cat on a mat", "a small kitten resting", ...]},
#   ...
# ]

# æ„å»ºä¸€ä¸ª img_id â†’ captions çš„å¿«é€Ÿç´¢å¼•
caption_map = {item["img_id"]: item["captions"] for item in captions_data}

assert len(features) == len(img_ids), "âŒ features ä¸ img_ids æ•°é‡ä¸ä¸€è‡´ï¼"
n_images = len(img_ids)
n_clusters = n_images // 3  # 1000 ç»„
print(f"âœ… å…± {n_images} å¼ å›¾ç‰‡ï¼Œå°†åˆ†ä¸º {n_clusters} ç»„ï¼Œæ¯ç»„ä¸‰å¼ ã€‚")

# === Step 2. KMeans èšç±» ===
print("ğŸ”¹ æ­£åœ¨è¿›è¡Œ KMeans èšç±»...")
kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10, max_iter=300)
kmeans.fit(features)
centers = kmeans.cluster_centers_

# === Step 3. æ¯ä¸ªä¸­å¿ƒå–3å¼ æœ€è¿‘çš„å›¾ç‰‡ ===
print("ğŸ”¹ ä¸ºæ¯ä¸ªèšç±»ä¸­å¿ƒåˆ†é…3å¼ æœ€ç›¸ä¼¼å›¾ç‰‡...")
used_indices = set()
groups = []

for i in tqdm(range(n_clusters)):
    available_idx = [idx for idx in range(n_images) if idx not in used_indices]
    available_features = features[available_idx]
    distances = np.linalg.norm(available_features - centers[i], axis=1)

    # å–æœ€è¿‘3å¼ 
    top3_indices = np.argsort(distances)[:3]
    selected_idx = [available_idx[j] for j in top3_indices]
    used_indices.update(selected_idx)

    group_images = []
    for j in selected_idx:
        img_id = img_ids[j]
        captions = caption_map.get(img_id, [])
        group_images.append({
            "img_id": img_id,
            "captions": captions
        })

    groups.append({
        "group_id": i,
        "images": group_images
    })

# === Step 4. è‹¥æœ‰æœªåˆ†é…å›¾ç‰‡ï¼Œéšæœºè¡¥é½åˆ°ä¸è¶³3çš„ç»„ ===
remaining = [idx for idx in range(n_images) if idx not in used_indices]
if remaining:
    print(f"âš ï¸ æœ‰ {len(remaining)} å¼ å›¾ç‰‡æœªåˆ†é…ï¼Œå°†éšæœºè¡¥å……å…¥ç»„ã€‚")
    random.shuffle(remaining)
    for g in groups:
        while len(g["images"]) < 3 and remaining:
            j = remaining.pop()
            img_id = img_ids[j]
            captions = caption_map.get(img_id, [])
            g["images"].append({
                "img_id": img_id,
                "captions": captions
            })

# === Step 5. ä¿å­˜ç»“æœ ===
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(groups, f, indent=2, ensure_ascii=False)

print(f"âœ… å·²å®Œæˆåˆ†ç»„ï¼Œå…± {len(groups)} ç»„ï¼Œæ¯ç»„3å¼ å›¾ç‰‡ã€‚")
print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶ï¼š{output_path}")
